---
layout: post
title: "VAE"
category: 공부하기
---

# 서론

Dall-E 2의 논문에 언급되어 있던 Diffusion model. GAN이나 Variation Auto Encoder같은 생성 모델 중 하나이다.

이 것이 어떤 것인지에 대해 더 알아보도록 하자.

...를 하려고 했는데, 사전 지식으로 VAE에 대해 알아볼 것을 요구하는 모양이다. Diffusion Model에 대해서는 가볍게만 알아보고, VAE에 대해서 알아보자.

# Diffusion Model: 간단한 이해

사실 이해하기 자체는 엄청 단순하다. GAN보다도 단순하다.

사진 편집같은걸 조금이라도 들어 본 사람이면 '가우시안 노이즈'라는 말을 들어 봤을꺼다.

사진을 흐리게 하는 것이다.

사진에 적은 양의 가우시안 노이즈를 계속 더하면 완전한 노이즈가 된다.

이제 이걸 거꾸로 하면 된다.

...하는 컨셉이다. 이제 여기에 밥 로스 사진을 붙여두고 '참 쉽죠?' 하면 된다.

# VAE: 간단한 이해

사실 아직도 완전한 납득은 안됐지만, 일단 가보자. 한참동안 뚫어져라 쳐다만 본다고 이 내용이 채워지는 것도 아니고.

 - 먼저 기본 구조는 Autoencoder와 같다. 입력이 있고, 점점 좁아져서 잠재 변수를 만들고, 다시 점점 넓어져서 이미지를 재구성한다. 이 때 잠재 변수는 나름의 의미를 가지게 된다.
 - AE와 다른 점은, 잠재 변수를 바로 만드는 대신, 잠재 변수의 위치를 평균과 표준편차로 나타내준다.
 - 이 평균과 표준편차를 이용해서 잠재 변수를 임의로 뽑아낸다.
 - 그리고 뽑아낸 잠재 변수를 이용해서 입력과 유사한 출력을 만들어 낸다.

대충 이렇게 정리할 수 있겠다.

왜 굳이? 표준편차까지 만든 다음에 임의로 뽑아내는가 싶은데, 나름 유용한 면이 있는 모양이다.

[이 링크](https://medium.com/@seyong.dev/vae-variational-auto-encoder-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-60032f19b9e3)를 참조한다.

그냥 AE에 비해서 이렇게 평균/표준편차를 계산해서 해주는게 예쁘게 오밀조밀 잘 모인다는 모양이다.

정확히는 잠재 변수의 분포가 정규분포의 모양이 되도록 학습을 시켜주기 때문에 오밀조밀 잘 모이게 된다는 것 같다.

모델 자체는 딱히 특별한 것은 없지만, 중간에 평균과 표준편차를 만들어주는 부분으로 인해서 생성에 좋은 잠재변수가 만들어진다.

아, 그리고 랜덤 샘플링을 하면서도 미분이 가능하게 하기 위해서 단순하지만 효과적인 트릭을 하나 사용한다.

평균과 표준편차에 맞춰서 샘플링을 하는 것이 아닌, N(0, 1)에 맞춰서 샘플링을 한 후 표준편차를 곱하고 평균을 더해주는 식이다.

Loss에 대한 단순한 조감은 [여기서](https://taeu.github.io/paper/deeplearning-paper-vae/) 볼 수 있다.

두 가지 loss를 사용하는데, 하나는 '이미지가 얼마나 닮았는가?'를 계산하고, 또 하나는 분포들(이미지에서 생성된 잠재공간의 분포 / 디코더의 사전 확률 (== 정규분포))이 가깝게 되도록 맞춰준다.

즉, 잠재 공간이 정규분포를 따르면서도 입/출력이 똑같아지도록 맞춰주는 loss를 가지고 있다.

이런 것들이 도출되는 과정이라던가, 그런게 까다롭고, 처음에 하고 싶었던 diffusion model과도 관련이 있지만... 그건 다음 시간에.

# 다음 시간

조금 더 수학적인 부분으로 들어가보자. 완전히 도출 과정을 따라갈 수는 없을 것 같지만, 대충 무슨 일이 일어나는지를 알 수 있으면 될 것이다.
